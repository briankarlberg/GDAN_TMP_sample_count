{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse power law to generate 100 predictions at each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latest draft of TMP\n",
    "https://docs.google.com/document/d/1LgIEkQ_pV7uQacI4SDf1Je-Ttk7d-1d2HlGrhMKuDfQ/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 7BCD_distribution_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from statistics import mean\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats # ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = pd.read_csv('data/TMP_cohort_colors_n26_20210228.csv',\n",
    "                     sep = ',', skiprows = 1, names = ['Cohort', 'Hexi'])\n",
    "\n",
    "sample_response_DF = pd.read_csv('data/sample_response_DF_20210805.tsv',\n",
    "                                          sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Hexi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC</td>\n",
       "      <td>#C1A72F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>#FAD2D9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>#ED2891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CESC</td>\n",
       "      <td>#F6B667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COADREAD</td>\n",
       "      <td>#9EDDF9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cohort     Hexi\n",
       "0       ACC  #C1A72F\n",
       "1      BLCA  #FAD2D9\n",
       "2      BRCA  #ED2891\n",
       "3      CESC  #F6B667\n",
       "4  COADREAD  #9EDDF9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort</th>\n",
       "      <th>Sample_size_100_accuracies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACC</td>\n",
       "      <td>{\"5\": [0.34285714285714286, 0.6901098901098901...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BLCA</td>\n",
       "      <td>{\"5\": [0.0, 0.8, 0.901010101010101, 0.35606060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRCA</td>\n",
       "      <td>{\"5\": [0.4499999999999999, 0.8967032967032967,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CESC</td>\n",
       "      <td>{\"5\": [0.6329966329966329, 1.0, 0.52, 0.355555...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COADREAD</td>\n",
       "      <td>{\"15\": [0.30416666666666664, 0.713043478260869...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cohort                         Sample_size_100_accuracies\n",
       "0       ACC  {\"5\": [0.34285714285714286, 0.6901098901098901...\n",
       "1      BLCA  {\"5\": [0.0, 0.8, 0.901010101010101, 0.35606060...\n",
       "2      BRCA  {\"5\": [0.4499999999999999, 0.8967032967032967,...\n",
       "3      CESC  {\"5\": [0.6329966329966329, 1.0, 0.52, 0.355555...\n",
       "4  COADREAD  {\"15\": [0.30416666666666664, 0.713043478260869..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_response_DF.head() # Processed F1 scores for 100 resamplings at each sample step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = [0,-1000,-1] # Define bounds\n",
    "upper = [.5,1000,0]\n",
    "# Define function, use to make 100 predictions at sample sizes 80 to 250\n",
    "def Y_acc(x, a, b, c):\n",
    "    Y_acc = (1-a)-b*x**c\n",
    "    return Y_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a Burr12 prediction for each of the 11 partial response cohorts at each of these sample sizes\n",
    "prediction_samples = [80,90,100,\n",
    "         110,120,130,140,150,160,170,180,\n",
    "         190,200,210,220,230,240,250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dists = [ # hard code in prediction block\n",
    "    'beta'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace fin_val_list with 80 - 250 step val list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_response_cohorts_to_predict = [('ACC', 0), # index corresponds to sample_response_DF\n",
    "                        ('CESC', 3),\n",
    "                        ('ESCC', 5),\n",
    "                        ('KIRP', 9),\n",
    "                        ('MESO', 14),\n",
    "                        ('PAAD', 16),\n",
    "                        ('PCPG', 17),\n",
    "                        ('SARC', 19),\n",
    "                        ('TGCT', 21),\n",
    "                        ('THYM', 23),\n",
    "                        ('UVM', 25),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_response_dct #out of order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_response # sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_response[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ACC'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size # fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(score_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8505184331797235,\n",
       " 0.8420716740304369,\n",
       " 0.8700063507320506,\n",
       " 0.8267141315360558,\n",
       " 0.8830498866213152,\n",
       " 0.876511861009021,\n",
       " 0.8525135857050751,\n",
       " 0.8661483897628477,\n",
       " 0.8566145634769348,\n",
       " 0.8815894840220594,\n",
       " 0.8483906273717176,\n",
       " 0.8525751353563991,\n",
       " 0.8653585754148188,\n",
       " 0.8540706605222734,\n",
       " 0.867251411202779,\n",
       " 0.8732303552743036,\n",
       " 0.8587127355650358,\n",
       " 0.8601460739334494,\n",
       " 0.8613348863118447,\n",
       " 0.8158008953875436,\n",
       " 0.8931656123566623,\n",
       " 0.8698437156064275,\n",
       " 0.896768149882904,\n",
       " 0.8621273166800967,\n",
       " 0.8607638546050367,\n",
       " 0.8988249845392702,\n",
       " 0.8211840986394557,\n",
       " 0.8814865811370036,\n",
       " 0.855354325043766,\n",
       " 0.8909634903802456,\n",
       " 0.8744045550093517,\n",
       " 0.8711836230645007,\n",
       " 0.8613767543099714,\n",
       " 0.866067035721171,\n",
       " 0.8889539095072693,\n",
       " 0.8569660224832638,\n",
       " 0.8373134328358209,\n",
       " 0.9052155949674933,\n",
       " 0.8884521286606171,\n",
       " 0.8605965563885641,\n",
       " 0.8585451314317372,\n",
       " 0.9124392080835727,\n",
       " 0.8892726321297749,\n",
       " 0.8661963842609004,\n",
       " 0.8980866663605332,\n",
       " 0.8983041609894141,\n",
       " 0.8822486772486773,\n",
       " 0.8438091626829896,\n",
       " 0.8877302112282189,\n",
       " 0.866609407769899,\n",
       " 0.8568189635404723,\n",
       " 0.8560335705163292,\n",
       " 0.8606132369437867,\n",
       " 0.8716240954366516,\n",
       " 0.8975662442396313,\n",
       " 0.8553568987403575,\n",
       " 0.834921601542238,\n",
       " 0.8408121446092904,\n",
       " 0.876874687824289,\n",
       " 0.8514237595543465,\n",
       " 0.8557453307002275,\n",
       " 0.8584486102133161,\n",
       " 0.867324906391388,\n",
       " 0.8964658538146439,\n",
       " 0.8727192796439391,\n",
       " 0.856222883512313,\n",
       " 0.8326823570130657,\n",
       " 0.8671896190693184,\n",
       " 0.85317796204113,\n",
       " 0.8860519522258233,\n",
       " 0.8986635993114613,\n",
       " 0.8763672170883199,\n",
       " 0.8742371449688524,\n",
       " 0.8830022918258212,\n",
       " 0.882039911308204,\n",
       " 0.8734947877162965,\n",
       " 0.8775761728951154,\n",
       " 0.8987561627495407,\n",
       " 0.8828571428571428,\n",
       " 0.8801652610954938,\n",
       " 0.8704637410519763,\n",
       " 0.8816798060199821,\n",
       " 0.8388762804391829,\n",
       " 0.8826190476190476,\n",
       " 0.8825269748139095,\n",
       " 0.8758215854647871,\n",
       " 0.8968133398776914,\n",
       " 0.8600915389564066,\n",
       " 0.9049651282624847,\n",
       " 0.8744671201814058,\n",
       " 0.883044185416102,\n",
       " 0.8830008242478739,\n",
       " 0.8329654330874131,\n",
       " 0.8710167707429483,\n",
       " 0.8708909853472754,\n",
       " 0.896479971641262,\n",
       " 0.8958479943701618,\n",
       " 0.8895156451999576,\n",
       " 0.890949772582775,\n",
       " 0.898409825468649]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8442874585731729,\n",
       " 0.7879271413517989,\n",
       " 0.7877469898522531,\n",
       " 0.8581391147244806,\n",
       " 0.7885551639072765,\n",
       " 0.8354203802733214,\n",
       " 0.8341549675443704,\n",
       " 0.8505184331797235]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_temp #?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fitting_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8505184331797235,\n",
       " 0.8420716740304369,\n",
       " 0.8700063507320506,\n",
       " 0.8267141315360558,\n",
       " 0.8830498866213152,\n",
       " 0.876511861009021,\n",
       " 0.8525135857050751,\n",
       " 0.8661483897628477,\n",
       " 0.8566145634769348,\n",
       " 0.8815894840220594,\n",
       " 0.8483906273717176,\n",
       " 0.8525751353563991,\n",
       " 0.8653585754148188,\n",
       " 0.8540706605222734,\n",
       " 0.867251411202779,\n",
       " 0.8732303552743036,\n",
       " 0.8587127355650358,\n",
       " 0.8601460739334494,\n",
       " 0.8613348863118447,\n",
       " 0.8158008953875436,\n",
       " 0.8931656123566623,\n",
       " 0.8698437156064275,\n",
       " 0.896768149882904,\n",
       " 0.8621273166800967,\n",
       " 0.8607638546050367,\n",
       " 0.8988249845392702,\n",
       " 0.8211840986394557,\n",
       " 0.8814865811370036,\n",
       " 0.855354325043766,\n",
       " 0.8909634903802456,\n",
       " 0.8744045550093517,\n",
       " 0.8711836230645007,\n",
       " 0.8613767543099714,\n",
       " 0.866067035721171,\n",
       " 0.8889539095072693,\n",
       " 0.8569660224832638,\n",
       " 0.8373134328358209,\n",
       " 0.9052155949674933,\n",
       " 0.8884521286606171,\n",
       " 0.8605965563885641,\n",
       " 0.8585451314317372,\n",
       " 0.9124392080835727,\n",
       " 0.8892726321297749,\n",
       " 0.8661963842609004,\n",
       " 0.8980866663605332,\n",
       " 0.8983041609894141,\n",
       " 0.8822486772486773,\n",
       " 0.8438091626829896,\n",
       " 0.8877302112282189,\n",
       " 0.866609407769899,\n",
       " 0.8568189635404723,\n",
       " 0.8560335705163292,\n",
       " 0.8606132369437867,\n",
       " 0.8716240954366516,\n",
       " 0.8975662442396313,\n",
       " 0.8553568987403575,\n",
       " 0.834921601542238,\n",
       " 0.8408121446092904,\n",
       " 0.876874687824289,\n",
       " 0.8514237595543465,\n",
       " 0.8557453307002275,\n",
       " 0.8584486102133161,\n",
       " 0.867324906391388,\n",
       " 0.8964658538146439,\n",
       " 0.8727192796439391,\n",
       " 0.856222883512313,\n",
       " 0.8326823570130657,\n",
       " 0.8671896190693184,\n",
       " 0.85317796204113,\n",
       " 0.8860519522258233,\n",
       " 0.8986635993114613,\n",
       " 0.8763672170883199,\n",
       " 0.8742371449688524,\n",
       " 0.8830022918258212,\n",
       " 0.882039911308204,\n",
       " 0.8734947877162965,\n",
       " 0.8775761728951154,\n",
       " 0.8987561627495407,\n",
       " 0.8828571428571428,\n",
       " 0.8801652610954938,\n",
       " 0.8704637410519763,\n",
       " 0.8816798060199821,\n",
       " 0.8388762804391829,\n",
       " 0.8826190476190476,\n",
       " 0.8825269748139095,\n",
       " 0.8758215854647871,\n",
       " 0.8968133398776914,\n",
       " 0.8600915389564066,\n",
       " 0.9049651282624847,\n",
       " 0.8744671201814058,\n",
       " 0.883044185416102,\n",
       " 0.8830008242478739,\n",
       " 0.8329654330874131,\n",
       " 0.8710167707429483,\n",
       " 0.8708909853472754,\n",
       " 0.896479971641262,\n",
       " 0.8958479943701618,\n",
       " 0.8895156451999576,\n",
       " 0.890949772582775,\n",
       " 0.898409825468649]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitting_scores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 100 predictions at each sample size for each cohort\n",
    "\n",
    "cohort_prdctns = {} # will be dict of dicts\n",
    "\n",
    "for cohort_tuple in partial_response_cohorts_to_predict:\n",
    "\n",
    "    cohort = cohort_tuple[0]\n",
    "    cohort_index = cohort_tuple[1] # to json converter\n",
    "    \n",
    "    accuracy_response_dct = {\n",
    "        int(k):[i for i in v] for k,v in json.loads( # json\n",
    "        sample_response_DF.iloc[cohort_index,1]).items()\n",
    "    }\n",
    "    accuracy_response = sorted(accuracy_response_dct.items())\n",
    "    \n",
    "    full_samples = [] # to green dots on plot\n",
    "    full_scores = []\n",
    "    \n",
    "    for i in list(range(0, len(accuracy_response))): # want for overlap on plot\n",
    "        full_samples.append(accuracy_response[i][0])\n",
    "        mean_score = mean(accuracy_response[i][1])\n",
    "        full_scores.append(mean_score)\n",
    "\n",
    "    sample_max = 14 # smp sz 75\n",
    "    sample_min = 6 # smp sz 35\n",
    "\n",
    "    fitting_samples = [] # This is 35 to 70 range\n",
    "    fitting_scores = []\n",
    "    \n",
    "    for i in list(range(sample_min, sample_max)): # Iterate fitting region\n",
    "        score_block = accuracy_response[i][1]\n",
    "        sample_size = accuracy_response[i][0]\n",
    "        fitting_samples.append(sample_size)\n",
    "        fitting_scores.append(score_block) # raw scores for this sample step size\n",
    "\n",
    "    hndrd_prdctns_smp_sz_n = []\n",
    "    \n",
    "    # Within cohort loop\n",
    "    \n",
    "    prdctn_dict = {}\n",
    "    \n",
    "    for resampling_idx in list(range(0,100)): # run the inverse power function 100 times\n",
    "\n",
    "        scores_temp = [] # 8 scores for each resampling on fitting window sample sizes\n",
    "\n",
    "        for tuple_n in accuracy_response[sample_min:sample_max]: # sorted dict, iterate 8 fitting window keys\n",
    "            \n",
    "            scores_temp.append(tuple_n[1][resampling_idx]) # Pull nth item from 100 score list value for each sample size in fitting window\n",
    "\n",
    "        front_end_param_set_n, _ = curve_fit( # Set parameters for each of 100 resamplings\n",
    "            Y_acc, # here is the inverse power function, set front-end parameters 100\n",
    "            fitting_samples,\n",
    "            scores_temp,\n",
    "            bounds=[lower,upper]\n",
    "        )\n",
    "        \n",
    "        y_predict = Y_acc(prediction_samples, *front_end_param_set_n)\n",
    "        \n",
    "        prdctn_dict[resampling_idx] = y_predict\n",
    "\n",
    "    cohort_prdctns[cohort] = prdctn_dict\n",
    "            \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,\n",
       " [0.8442874585731729,\n",
       "  0.7910714285714285,\n",
       "  0.8346130060415775,\n",
       "  0.8575871740518927,\n",
       "  0.8480298786181139,\n",
       "  0.8319074522464353,\n",
       "  0.6899018087855296,\n",
       "  0.7816575230316091,\n",
       "  0.8075187969924812,\n",
       "  0.8338106681441045,\n",
       "  0.8346341375259781,\n",
       "  0.8674778400130513,\n",
       "  0.8071428571428572,\n",
       "  0.7700432900432901,\n",
       "  0.7644526814933547,\n",
       "  0.7178412698412698,\n",
       "  0.7671393740359258,\n",
       "  0.8255479969765684,\n",
       "  0.785245956089946,\n",
       "  0.7364604023427553,\n",
       "  0.9570800181326499,\n",
       "  0.7618433179723503,\n",
       "  0.867765724908582,\n",
       "  0.8080155138978669,\n",
       "  0.830107251070106,\n",
       "  0.8090969215969216,\n",
       "  0.7751735270379337,\n",
       "  0.8639479119263486,\n",
       "  0.8853781512605043,\n",
       "  0.8649765422385407,\n",
       "  0.7639564916875841,\n",
       "  0.7668913663469018,\n",
       "  0.7804639804639804,\n",
       "  0.9113334129638477,\n",
       "  0.881057789039619,\n",
       "  0.7398159263705483,\n",
       "  0.8669064039408867,\n",
       "  0.8824670437194898,\n",
       "  0.8554644450848375,\n",
       "  0.8386715797430084,\n",
       "  0.8029931972789116,\n",
       "  0.779961714415496,\n",
       "  0.8435827664399093,\n",
       "  0.7522208024533606,\n",
       "  0.8436098419467289,\n",
       "  0.8697061267658834,\n",
       "  0.8044926349004082,\n",
       "  0.8046152747801923,\n",
       "  0.7145095457537854,\n",
       "  0.8952380952380953,\n",
       "  0.8463282748997035,\n",
       "  0.801754939713402,\n",
       "  0.927598433312719,\n",
       "  0.7416367211336362,\n",
       "  0.865936101250193,\n",
       "  0.9288019526747575,\n",
       "  0.8148419481752814,\n",
       "  0.7814733414733415,\n",
       "  0.8418990739259496,\n",
       "  0.7640103660511824,\n",
       "  0.9153197278911562,\n",
       "  0.8517254632323126,\n",
       "  0.7248315140009493,\n",
       "  0.7726559155130583,\n",
       "  0.756397895455697,\n",
       "  0.8999172870140613,\n",
       "  0.733329852567826,\n",
       "  0.8546666666666667,\n",
       "  0.7925415806876663,\n",
       "  0.7841758241758241,\n",
       "  0.8239415507183447,\n",
       "  0.8977127350261679,\n",
       "  0.7041988701835249,\n",
       "  0.8084212995543045,\n",
       "  0.8429741019214704,\n",
       "  0.7525423728813561,\n",
       "  0.7887391774891774,\n",
       "  0.755374149659864,\n",
       "  0.8540109377084166,\n",
       "  0.8714311066041324,\n",
       "  0.7868623505740325,\n",
       "  0.8190859074682001,\n",
       "  0.7893085203430031,\n",
       "  0.7323711663659894,\n",
       "  0.8552890583291574,\n",
       "  0.9141798403164585,\n",
       "  0.7705998919113674,\n",
       "  0.8474033515845363,\n",
       "  0.7778328840970351,\n",
       "  0.8253186813186812,\n",
       "  0.7807577170339107,\n",
       "  0.9262166405023547,\n",
       "  0.7750655384104862,\n",
       "  0.8616863055335805,\n",
       "  0.9281393060368801,\n",
       "  0.7945578231292517,\n",
       "  0.7674681240190759,\n",
       "  0.812067840834964,\n",
       "  0.8726432022084196,\n",
       "  0.8014357233091148])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                   Type         Data/Info\n",
      "-------------------------------------------------\n",
      "Y_acc                      function     <function Y_acc at 0x7fa8755731e0>\n",
      "accuracy_response          list         n=15\n",
      "accuracy_response_dct      dict         n=15\n",
      "cohort                     str          ACC\n",
      "cohort_index               int          0\n",
      "cohort_tuple               tuple        n=2\n",
      "colors                     DataFrame          Cohort     Hexi\\n0 <...>C7\\n25       UVM  #009444\n",
      "fitting_samples            list         n=8\n",
      "fitting_scores             list         n=8\n",
      "fitting_scores_ave         list         n=8\n",
      "full_samples               list         n=15\n",
      "full_scores                list         n=15\n",
      "i                          int          13\n",
      "idx                        int          0\n",
      "json                       module       <module 'json' from '/Use<...>hon3.7/json/__init__.py'>\n",
      "list_of_dists              list         n=1\n",
      "lower                      list         n=3\n",
      "mean                       function     <function mean at 0x7fa87554c8c8>\n",
      "mean_score                 float        0.8764772554926882\n",
      "partial_response_predict   list         n=11\n",
      "pd                         module       <module 'pandas' from '/U<...>ages/pandas/__init__.py'>\n",
      "plt                        module       <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "sample_max                 int          14\n",
      "sample_min                 int          6\n",
      "sample_response_DF         DataFrame          Cohort             <...>2, 0.52, 0.35555555555...\n",
      "sample_size                int          70\n",
      "score_block                list         n=100\n",
      "stats                      module       <module 'scipy.stats' fro<...>scipy/stats/__init__.py'>\n",
      "upper                      list         n=3\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel D, Predict with Burr12\n",
    "# This cell plots a histogram\n",
    "# From 7BCD_distribution_search.7.ipynb\n",
    "\n",
    "for i in list_of_dists:\n",
    "    dist = getattr(stats, i)\n",
    "    \n",
    "    dist_list = []\n",
    "    cohort_list = []\n",
    "\n",
    "    raw_mean_list = []\n",
    "    raw_median_list = []\n",
    "    \n",
    "    peak_val_list = []\n",
    "    actual_val_list = []\n",
    "\n",
    "    for j, fin_tup in enumerate(fin_val_list):\n",
    "\n",
    "        final_vals = fin_tup[1]\n",
    "\n",
    "        cohort = fin_tup[0]\n",
    "\n",
    "        distri = i\n",
    "\n",
    "        fig = plt.figure(figsize=(5, 1.75))\n",
    "        ax = plt.subplot(111)\n",
    "\n",
    "        a, b = dist.fit(final_vals, floc=0, fscale=1)[:2]\n",
    "        ax.plot(np.linspace(min(final_vals), max(final_vals), 100),\n",
    "                            dist.pdf(np.linspace(min(final_vals), max(final_vals), 100),\n",
    "                                           a, b), 'k', linewidth = 2)\n",
    "\n",
    "        mxlst = list(dist.pdf(np.linspace(min(final_vals), max(final_vals), 100), a, b))\n",
    "\n",
    "        y_hist, x_hist, _ = ax.hist(final_vals, alpha=0.5, color='red', bins=20, density=True)\n",
    "\n",
    "        mxv = max(mxlst)\n",
    "        x_ndx = mxlst.index(mxv)\n",
    "        xlst = np.linspace(min(final_vals), max(final_vals), 100)\n",
    "\n",
    "        xd = [xlst[x_ndx],xlst[x_ndx]]\n",
    "        yd = [0, mxv]\n",
    "        plt.plot(xd,yd,'--',linewidth = 2.5)\n",
    "\n",
    "        ax.invert_xaxis()\n",
    "        \n",
    "        plt.xticks(rotation = 90, size=11.5)\n",
    "        plt.ylabel('Prediction frequency', size = 15.5)\n",
    "        plt.xlabel('F1 score', size = 15.5, rotation = 180)\n",
    "        ax.yaxis.set_label_position(\"right\")\n",
    "        ax.yaxis.tick_right()\n",
    "        plt.yticks(rotation = 90, size=11.5)\n",
    "        plt.locator_params(axis='y', nbins=3) # ACC\n",
    "\n",
    "        fig.patch.set_facecolor('white')\n",
    "        fig.patch.set_alpha(0.6)\n",
    "        \n",
    "        ax.patch.set_facecolor('white')\n",
    "        ax.patch.set_alpha(0.7)\n",
    "        \n",
    "        plt.savefig('./version_6/'+cohort+'_'+distri+'_distr_trnslc2.png',\n",
    "                    facecolor=fig.get_facecolor(), edgecolor='none',\n",
    "                    bbox_inches = 'tight')\n",
    "        \n",
    "        dist_list.append(distri)\n",
    "        cohort_list.append(cohort)\n",
    "\n",
    "        raw_mean_list.append(mean(final_vals))\n",
    "        raw_median_list.append(statistics.median(final_vals))\n",
    "        \n",
    "        peak_val_list.append(xlst[x_ndx])\n",
    "        actual_val_list.append(full_scores_last[j][1])\n",
    "        \n",
    "    stor_dict = {\n",
    "        'Dist': dist_list,\n",
    "        'Cohort': cohort_list,\n",
    "\n",
    "        'Raw_mean': raw_mean_list,\n",
    "        'Raw_median': raw_median_list,\n",
    "\n",
    "        'Peak_val': peak_val_list,\n",
    "        'Actl_val': actual_val_list, \n",
    "    }\n",
    "        \n",
    "    storDF = pd.DataFrame( stor_dict )\n",
    "    print(distri)\n",
    "    print(mean_squared_error(storDF.Actl_val, storDF.Peak_val))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code parking lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative extraction for plot (template)\n",
    "for prdctn_smp_sz in prediction_samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add resampling key with corresponding parameter set value\n",
    "front_end_parameters[resampling_idx] = front_end_param_set_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 2, prior to switching inverse law to predict 100 times at each prediction sample size\n",
    "\n",
    "# generate 100 predictions at each sample size for each cohort\n",
    "\n",
    "cohort_key_hndrd_prdctns_each_smp_szs_80_to_250 = {} # will be dict of dicts\n",
    "\n",
    "for cohort_tuple in partial_response_cohorts_to_predict:\n",
    "    \n",
    "    hndrd_prdctns_each_smp_szs_80_to_250 = {} # smp sz  = keys\n",
    "                                              # lsts of hndrd prctns= vals\n",
    "    cohort = cohort_tuple[0]\n",
    "    cohort_index = cohort_tuple[1] # to json converter\n",
    "    \n",
    "    accuracy_response_dct = {\n",
    "        int(k):[i for i in v] for k,v in json.loads( # json\n",
    "        sample_response_DF.iloc[cohort_index,1]).items()\n",
    "    }\n",
    "    accuracy_response = sorted(accuracy_response_dct.items())\n",
    "    \n",
    "    full_samples = [] # to green dots on plot\n",
    "    full_scores = []\n",
    "    \n",
    "    for i in list(range(0, len(accuracy_response))): # want for overlap on plot\n",
    "        full_samples.append(accuracy_response[i][0])\n",
    "        mean_score = mean(accuracy_response[i][1])\n",
    "        full_scores.append(mean_score)\n",
    "\n",
    "    sample_max = 14 # smp sz 75\n",
    "    sample_min = 6 # smp sz 35\n",
    "\n",
    "    fitting_samples = [] # This is 35 to 70 range\n",
    "    fitting_scores = []\n",
    "    \n",
    "    for i in list(range(sample_min, sample_max)): # Iterate fitting region\n",
    "        score_block = accuracy_response[i][1]\n",
    "        sample_size = accuracy_response[i][0]\n",
    "        fitting_samples.append(sample_size)\n",
    "        fitting_scores.append(score_block) # raw scores for this sample step size\n",
    "\n",
    "#     y_predictions = []         #                             <---------- y_predictions\n",
    "#     y_predictions_srs = pd.Series(dtype = 'float64')\n",
    "#     y_std = [] # ?\n",
    "#     y_final_100 = [] # ?\n",
    "    \n",
    "#     front_end_parameters = {} # 100 resampling keys, inverse power parameters as keys, NOT necessary to store, delete\n",
    "    hndrd_prdctns_smp_sz_n = []\n",
    "    \n",
    "    # Within cohort loop\n",
    "    \n",
    "    for resampling_idx in list(range(0,100)): # run the inverse power function 100 times\n",
    "\n",
    "        scores_temp = [] # 8 scores for each resampling on fitting window sample sizes\n",
    "\n",
    "        for tuple_n in accuracy_response[sample_min:sample_max]: # sorted dict, iterate 8 fitting window keys\n",
    "            \n",
    "            scores_temp.append(tuple_n[1][resampling_idx]) # Pull nth item from 100 score list value for each sample size in fitting window\n",
    "\n",
    "        front_end_param_set_n, _ = curve_fit(\n",
    "            Y_acc, # here is the inverse power function, set front-end parameters 100 times\n",
    "            fitting_samples,\n",
    "            scores_temp,\n",
    "            bounds=[lower,upper]\n",
    "        )\n",
    "#         x_fit = np.linspace(fitting_samples[0], fitting_samples[-1], 50)\n",
    "#         y_fit = Y_acc(x_fit, *front_end_param_set_n) # 100 green lines\n",
    "        \n",
    "#         for prdctn_smp_sz in prediction_samples:\n",
    "        \n",
    "        y_predict = Y_acc(prediction_samples, *front_end_param_set_n) # Fit to each param set, old DELETE        \n",
    "        \n",
    "#         y_predict = Y_acc(prediction_samples, *front_end_param_set_n) # Fit to each param set, old DELETE\n",
    "#         y_predictions.append(y_predict) # 100 red lines, old DELETE\n",
    "        break\n",
    "#         y_predictions_srs[str(resampling_idx)] = y_predict\n",
    "    break\n",
    "        \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83821879, 0.84189478, 0.84511223, 0.84796633, 0.85052597,\n",
       "       0.85284253, 0.85495532, 0.856895  , 0.85868596, 0.86034789,\n",
       "       0.8618969 , 0.86334631, 0.8647073 , 0.8659893 , 0.86720032,\n",
       "       0.86834728, 0.86943614, 0.87047208])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output from checkpoint 2\n",
    "y_predict # one of 100 prediction sets for 80 through 250 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checkpoint 1 , partially modified template\n",
    "\n",
    "for cohort_tuple in partial_response_predict: #? deleted idx\n",
    "    \n",
    "    cohort = cohort_tuple[0] #? - COAD and HNSC check\n",
    "    cohort_index = cohort_tuple[1] # good\n",
    "    \n",
    "    accuracy_response_dct = {\n",
    "        int(k):[i for i in v] for k,v in json.loads( # json\n",
    "        sample_response_DF.iloc[cohort_index,1]).items()\n",
    "    }\n",
    "    accuracy_response = sorted(accuracy_response_dct.items())\n",
    "    \n",
    "    full_samples = []\n",
    "    full_scores = []\n",
    "    \n",
    "    for i in list(range(0, len(accuracy_response))):\n",
    "        full_samples.append(accuracy_response[i][0])\n",
    "        mean_score = mean(accuracy_response[i][1])\n",
    "        full_scores.append(mean_score)\n",
    "#         mean_temp = round(mean_score, 3) # ?\n",
    "#         full_scores.append(mean_temp) Delete\n",
    "\n",
    "    sample_max = 14 # 13 is default, max\n",
    "    sample_min = 6 \n",
    "#     full_scores_last.append( ( cohort, full_scores[-1] ) ) #    <-----   Important DELETE\n",
    "#     partial_scores_last.append( ( cohort, full_scores[-1] ) ) # ?\n",
    "\n",
    "#     # Set fitting region by index\n",
    "#     if cohort not in ['COADREAD', 'HNSC']:\n",
    "#         sample_max = 14 #14 is default, max\n",
    "#         sample_min = 6 #5 is default # BRCA 14,4 and 13,4 is good, 14,7 too\n",
    "#     else:\n",
    "#         sample_max = 13 # 13 is default, max\n",
    "#         sample_min = 5  # 4 is dfault      \n",
    "\n",
    "    fitting_samples = [] # This is 35 to 70 range\n",
    "    fitting_scores = []\n",
    "#     fitting_scores_ave = [] # ?\n",
    "    \n",
    "    for i in list(range(sample_min, sample_max)): # Iterate fitting region\n",
    "        score_block = accuracy_response[i][1]\n",
    "        sample_size = accuracy_response[i][0]\n",
    "        fitting_samples.append(sample_size)\n",
    "        fitting_scores.append(score_block) # raw scores for this sample step size\n",
    "        \n",
    "    prediction_samples = [80,90,100,\n",
    "                     110,120,130,140,150,160,170,180,\n",
    "                     190,200,210,220,230,240,250]\n",
    "\n",
    "#     front_end_mean_params, _ = curve_fit(Y_acc,\n",
    "#                                  fitting_samples,\n",
    "#                                  fitting_scores_ave, # <---------- bingo\n",
    "#                                     bounds=[lower,upper])\n",
    "\n",
    "\n",
    "    front_end_parameters = {}\n",
    "    y_predictions = []         #                             <---------- y_predictions\n",
    "    y_predictions_srs = pd.Series(dtype = 'float64')\n",
    "    y_std = [] # ?\n",
    "    y_final_100 = [] # ?\n",
    "    for resampling_idx in list(range(0,100)):\n",
    "\n",
    "        scores_temp = [] # 100 scores for each sample size on restricted front-end portion of curve\n",
    "\n",
    "        for tuple_n in accuracy_response[sample_min:sample_max]:\n",
    "            scores_temp.append(tuple_n[1][resampling_idx])\n",
    "\n",
    "        front_end_param_set_n, _ = curve_fit(Y_acc,\n",
    "                                 fitting_samples,\n",
    "                                 scores_temp,\n",
    "                                    bounds=[lower,upper])\n",
    "        front_end_parameters[resampling_idx] = front_end_param_set_n\n",
    "\n",
    "        # Now, plot all 100 front-end fitting curves and compare to actual \n",
    "        x_fit = np.linspace(fitting_samples[0], fitting_samples[-1], 50)\n",
    "        y_fit = Y_acc(x_fit, *front_end_param_set_n) # 100 green lines\n",
    "        \n",
    "        y_predict = Y_acc(prediction_samples, *front_end_param_set_n) # Fit to each param set\n",
    "        y_predictions.append(y_predict) # 100 red lines\n",
    "        \n",
    "        y_predictions_srs[str(resampling_idx)] = y_predict\n",
    "#         y_final_100.append(y_predict[-1])                     # <---- Turn on for full scores\n",
    "    \n",
    "#     final_vals = []\n",
    "#     for i in y_predictions:\n",
    "#         final_val = i[-1]\n",
    "#         final_vals.append(final_val)\n",
    "#     stor_tup = (cohort, final_vals)\n",
    "#     fin_val_list.append(stor_tup)  # Keep!    ******************************\n",
    "        \n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
